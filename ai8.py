# streamlit_webrtc_vosk_app.py
# ØªØ·Ø¨ÙŠÙ‚ Streamlit Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Vosk
# Ù…Ù„Ø§Ø­Ø¸Ø§Øª: ÙŠØ¹Ù…Ù„ Ù…Ø¹ streamlit-webrtc. Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ÙˆØ¬ÙˆØ¯ Ù†Ù…ÙˆØ°Ø¬ Vosk Ù…Ø­Ù„ÙŠØ§Ù‹
# Ø£Ùˆ Ø±ÙØ¹Ù‡ ÙŠØ¯ÙˆÙŠØ§Ù‹ (Ø£Ùˆ Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„) Ù„Ø£Ù† Ø±ÙØ¹Ù‡ Ø¥Ù„Ù‰ GitHub ØºØ§Ù„Ø¨Ø§Ù‹ Ù…Ø§ ÙŠÙƒÙˆÙ† ÙƒØ¨ÙŠØ± Ø§Ù„Ø­Ø¬Ù….

import streamlit as st
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
import av
import numpy as np
import tempfile
import wave
import os
import json
from pathlib import Path
from vosk import Model, KaldiRecognizer
import threading
import zipfile
import requests

# ----------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© -----------------------
st.set_page_config(page_title="Ø³Ø§Ù†Ø¯ÙŠ - Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ ØµÙˆØªÙŠ", layout="wide")
st.title("ğŸ¦· Ø³Ø§Ù†Ø¯ÙŠ â€” Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ ØµÙˆØªÙŠ (Streamlit + WebRTC)")
st.markdown("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­ ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Vosk.")

# ----------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ -----------------------
MODEL_DIR = Path("./vosk-model-ar-mgb2")  # ØºÙŠÙ‘Ø±ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…Ø®ØªÙ„Ù
MODEL_ZIP_NAME = "vosk-model-ar-mgb2.zip"

# ----------------------- ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© -----------------------

def load_vosk_model(model_path: Path):
    """Ø­Ø§ÙˆÙ„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Vosk Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯"""
    try:
        if not model_path.exists():
            return None, "Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
        model = Model(str(model_path))
        return model, None
    except Exception as e:
        return None, str(e)


def download_and_extract_zip(url: str, extract_to: Path):
    """Ø­Ù…Ù‘Ù„ zip Ù…Ù† URL ÙˆÙÙƒ Ø¶ØºØ·Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯."""
    try:
        r = requests.get(url, stream=True, timeout=60)
        r.raise_for_status()
        total = int(r.headers.get('content-length', 0))
        with open(MODEL_ZIP_NAME, 'wb') as f:
            downloaded = 0
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
        # ÙÙƒ Ø§Ù„Ø¶ØºØ·
        with zipfile.ZipFile(MODEL_ZIP_NAME, 'r') as zf:
            zf.extractall(path=str(extract_to.parent))
        return True, None
    except Exception as e:
        return False, str(e)

# ----------------------- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­ÙƒÙ… -----------------------
st.sidebar.header("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
model_status = st.sidebar.empty()

# Ø®ÙŠØ§Ø±Ø§Øª Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
st.sidebar.write("Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ ÙŠÙ…ÙƒÙ†Ùƒ: \n - Ø±ÙØ¹ Ù…Ù„Ù zip Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ø¨Ø± uploader  - Ø£Ùˆ Ø¥Ø¹Ø·Ø§Ø¡ Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø± (HTTP/HTTPS) Ù„ÙŠØªÙ… ØªÙ†Ø²ÙŠÙ„Ù‡ Ù‡Ù†Ø§")

uploaded_model = st.sidebar.file_uploader("Ø±ÙØ¹ Ù…Ù„Ù Ù…ÙˆØ¯ÙŠÙ„ zip (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", type=["zip"]) 
download_url = st.sidebar.text_input("Ø£Ùˆ Ø¶Ø¹ Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")

# Ø²Ø± Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¬Ø§Ù‡Ø²ÙŠØ© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
if st.sidebar.button("ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„"):
    st.experimental_rerun()

# Process uploaded zip
if uploaded_model is not None:
    with open(MODEL_ZIP_NAME, 'wb') as f:
        f.write(uploaded_model.read())
    st.sidebar.success("ØªÙ… Ø±ÙØ¹ zip. Ø¬Ø§Ø±ÙŠ ÙÙƒ Ø§Ù„Ø¶ØºØ·...")
    try:
        with zipfile.ZipFile(MODEL_ZIP_NAME, 'r') as zf:
            zf.extractall(path='.')
        st.sidebar.success("ØªÙ… ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„. ØªØ£ÙƒØ¯ÙŠ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯.")
    except Exception as e:
        st.sidebar.error(f"ÙØ´Ù„ ÙÙƒ Ø§Ù„Ø¶ØºØ·: {e}")

# Download from URL if provided
if download_url:
    st.sidebar.info("Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·...")
    ok, err = download_and_extract_zip(download_url, MODEL_DIR)
    if ok:
        st.sidebar.success("Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ù„ÙÙƒ.")
    else:
        st.sidebar.error(f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {err}")

# Attempt to load model
model, err = load_vosk_model(MODEL_DIR)
if model:
    model_status.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {MODEL_DIR}")
else:
    model_status.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Vosk. Ø¶Ø¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø£Ùˆ Ø§Ø±ÙØ¹Ù‡ ÙƒÙ€ zip.")
    if err:
        st.sidebar.error(f"Ø®Ø·Ø£ Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: {err}")

# ----------------------- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„ -----------------------
st.header("ğŸ¤ ØªØ³Ø¬ÙŠÙ„ ÙˆØªØ´ØºÙŠÙ„ Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­")
st.markdown("Ø§Ø¶ØºØ·ÙŠ Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„Ø³Ù…Ø§Ø­ ÙÙŠ Ø§Ù„Ù…ØªØµÙØ­ Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†. ÙŠÙ…ÙƒÙ†Ùƒ Ø¥ÙŠÙ‚Ø§Ù ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ø­Ø±ÙŠØ©.")

# Ù…ØªØºÙŠØ±Ø§Øª Ø­Ø§Ù„Ø© Ù…Ø´ØªØ±ÙƒØ©
if 'transcriptions' not in st.session_state:
    st.session_state.transcriptions = []
if 'last_wav' not in st.session_state:
    st.session_state.last_wav = None

# Ù…ÙƒÙˆÙ‘Ù† Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª Ø§Ù„ÙˆØ§Ø±Ø¯
class RecorderProcessor(AudioProcessorBase):
    def __init__(self):
        self.buffer = []
        self.lock = threading.Lock()

    def recv_audio(self, frame: av.AudioFrame) -> av.AudioFrame:
        # Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy Ù…Ù† Ø§Ù„Ø¥Ø·Ø§Ø± (float32)
        arr = frame.to_ndarray()
        # arr shape: (channels, samples) Ø£Ùˆ (samples,) Ø­Ø³Ø¨ Ø§Ù„Ø¥Ø·Ø§Ø±
        # Ø³Ù†Ø­ÙˆÙ‘Ù„Ù‡Ø§ Ø¥Ù„Ù‰ 16-bit PCM mono
        if arr.ndim > 1:
            arr_mono = np.mean(arr, axis=0)
        else:
            arr_mono = arr
        # Normalize float32 [-1,1] -> int16
        int16 = (arr_mono * 32767).astype(np.int16)
        with self.lock:
            self.buffer.append(int16.tobytes())
        return frame

    def dump_wav(self, filename, samplerate=48000):
        # streamlit-webrtc ÙŠØ³ØªØ®Ø¯Ù… ØºØ§Ù„Ø¨Ù‹Ø§ 48000Hz
        with self.lock:
            data = b"".join(self.buffer)
            self.buffer = []
        if not data:
            return False
        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(samplerate)
            wf.writeframes(data)
        return True

# Ø¨Ø¯Ø§ÙŠØ© WebRTC streamer
webrtc_ctx = webrtc_streamer(
    key="audio",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=1024,
    media_stream_constraints={"audio": True, "video": False},
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    audio_processor_factory=RecorderProcessor,
)

# Ø£Ø²Ø±Ø§Ø± Ø­ÙØ¸ ÙˆÙ…Ø­Ùˆ
col1, col2 = st.columns([1,1])
with col1:
    if st.button("ğŸ”´ Ø§Ø­ÙØ¸ Ø¢Ø®Ø± ØªØ³Ø¬ÙŠÙ„ WAV"):
        if webrtc_ctx.audio_processor:
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
            ok = webrtc_ctx.audio_processor.dump_wav(tmp.name, samplerate=48000)
            if ok:
                st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ: {tmp.name}")
                st.session_state.last_wav = tmp.name
            else:
                st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµÙˆØªÙŠØ© Ù„Ø­ÙØ¸Ù‡Ø§.")
        else:
            st.error("âš ï¸ Ù„Ù… ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØª Ø¨Ø¹Ø¯.")

with col2:
    if st.button("ğŸ—‘ï¸ Ø£Ø²Ù„ Ø¢Ø®Ø± ØªØ³Ø¬ÙŠÙ„ Ù…Ø­ÙÙˆØ¸"):
        if st.session_state.last_wav and os.path.exists(st.session_state.last_wav):
            os.unlink(st.session_state.last_wav)
        st.session_state.last_wav = None
        st.success("ØªÙ… Ø§Ù„Ù…Ø³Ø­.")

st.markdown("---")

# Ø±ÙØ¹ Ù…Ù„Ù WAV Ø¨Ø¯Ù„Ø§ Ù…Ù† Ø§Ù„ØªØ³Ø¬ÙŠÙ„
uploaded_wav = st.file_uploader("Ø£Ùˆ Ø§Ø±ÙØ¹ Ù…Ù„Ù WAV Ø¬Ø§Ù‡Ø² Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", type=["wav"]) 
if uploaded_wav is not None:
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    tmp.write(uploaded_wav.read())
    tmp.close()
    st.session_state.last_wav = tmp.name
    st.success("ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù.")

# Ø²Ø± ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ
if st.button("ğŸ” ØªØ­ÙˆÙŠÙ„ Ø¢Ø®Ø± Ù…Ù„Ù Ø¥Ù„Ù‰ Ù†Øµ"):
    if not st.session_state.last_wav:
        st.warning("Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù ØµÙˆØªÙŠ. Ø³Ø¬Ù‘Ù„ÙŠ Ø£Ùˆ Ø§Ø±ÙØ¹ÙŠ Ù…Ù„Ù Ø£ÙˆÙ„Ø§Ù‹.")
    else:
        wav_path = st.session_state.last_wav
        st.info(f"Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø©: {wav_path}")
        if model is None:
            st.error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Vosk Ù…Ø­Ù…Ù‘Ù„. ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø£Ùˆ ØªÙ†Ø²ÙŠÙ„Ù‡ Ø£ÙˆÙ„Ø§Ù‹.")
        else:
            try:
                # Ø§ÙØªØ­ WAV ÙˆØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø©
                with wave.open(wav_path, 'rb') as wf:
                    sample_rate = wf.getframerate()
                    frames = wf.readframes(wf.getnframes())
                # Ù„Ùˆ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø© Ù„ÙŠØ³ 16000ØŒ Ù†Ø­ØªØ§Ø¬ Ù„ØªØ­ÙˆÙŠÙ„. Vosk ÙŠÙØ¶Ù„ 16000.
                if sample_rate != 16000:
                    st.info(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø© {sample_rate}Hz â€” Ø³ÙŠØ¬Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ 16000Hz.")
                    # Ø§Ø³ØªØ®Ø¯Ù… Ø¥Ø¹Ø§Ø¯Ø© Ø¹ÙŠÙ‘Ù†Ø© Ø¨Ø³ÙŠØ·Ø©: ØªØ­ÙˆÙŠÙ„ Ø¹Ø¨Ø± numpy (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø£Ø³ÙˆØ£ Ø¬ÙˆØ¯Ø©)
                    import audioop
                    frames = audioop.ratecv(frames, 2, 1, sample_rate, 16000, None)[0]
                    sample_rate = 16000
                rec = KaldiRecognizer(model, sample_rate)
                rec.SetWords(False)
                # Feed data in chunks
                CHUNK = 4000
                i = 0
                text_parts = []
                for start in range(0, len(frames), CHUNK):
                    chunk = frames[start:start+CHUNK]
                    if rec.AcceptWaveform(chunk):
                        res = json.loads(rec.Result())
                        text_parts.append(res.get('text', ''))
                final = json.loads(rec.FinalResult())
                text_parts.append(final.get('text', ''))
                transcript = ' '.join([p for p in text_parts if p])
                if transcript.strip() == '':
                    st.warning('Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙƒÙ„Ø§Ù… ÙˆØ§Ø¶Ø­ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„.')
                else:
                    st.session_state.transcriptions.append(transcript)
                    st.success('âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ:')
                    st.write(transcript)
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­ÙˆÙŠÙ„: {e}")

# Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„
st.markdown("---")
st.subheader("ğŸ“‹ Ø³Ø¬Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø©")
for i, t in enumerate(reversed(st.session_state.transcriptions)):
    st.write(f"{len(st.session_state.transcriptions)-i}. {t}")

st.markdown("---")
st.caption("Ù…Ù„Ø§Ø­Ø¸Ø§Øª: \n- Streamlit Cloud Ù„Ø§ ÙŠØ¯Ø¹Ù… Ø§Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù‡Ø§Ø±Ø¯ÙˆÙŠØ± Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø§Ø¯Ù…Ø› Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙŠØªÙ… Ù…Ù† Ù…ØªØµÙØ­ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….\n- ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…ÙˆØ¯ÙŠÙ„ Vosk ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± Ø±ÙØ¹ zip/Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ.")
